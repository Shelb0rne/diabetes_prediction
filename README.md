# diabetes_prediction
## Описание проекта
Проект посвящён задаче бинарной классификации — определению вероятности наличия диабета у пациента на основе медицинских и поведенческих показателей. Используется открытый набор данных diabetes.csv, содержащий 21 числовой признак (например, возраст, индекс массы тела, уровень физической активности, наличие гипертонии и т.д.).

В ходе работы проводится полный цикл машинного обучения:

— предварительная обработка данных, масштабирование признаков и анализ корреляций;

— разделение выборки на обучающую, валидационную и тестовую части;

— обучение и сравнение нескольких моделей: логистическая регрессия, решающее дерево, случайный лес, LightGBM и нейронная сеть на PyTorch

— подбор гиперпараметров и оптимальных порогов классификации по метрике F1;

— итоговая оценка точности, F1 и ROC-AUC на трёх выборках.

Проект демонстрирует, как с помощью различных алгоритмов можно решать задачу медицинской диагностики, сравнивая их эффективность и интерпретируемость.

## Описание данных

Для обучения использовался датасет diabetes.csv, включающий медицинские, демографические и поведенческие характеристики более чем 250 тысяч человек.
Целевая переменная — Diabetes_binary:

0 — человек здоров,

1 — диабет диагностирован.

Распределение целевого признака неравномерное — здоровых примерно в 5 раз больше, чем людей с диабетом:
<img width="720" height="538" alt="Снимок экрана 2025-10-08 154454" src="https://github.com/user-attachments/assets/716fd53b-c92a-47c9-ad5e-c72d6cabd715" />


Основные признаки:

- HighBP — наличие высокого давления

- HighChol — высокий уровень холестерина

- BMI — индекс массы тела

GenHlth — самооценка общего состояния здоровья

- DiffWalk — трудности при ходьбе на короткие расстояния

- Age, Sex, Education, Income — социально-демографические переменные

- Поведенческие факторы: Smoker, PhysActivity, Fruits, Veggies, HvyAlcoholConsump и др.

По результатам корреляционного анализа наиболее связанные с целевой переменной признаки:
HighBP, HighChol, BMI, GenHlth, DiffWalk.

<img width="905" height="923" alt="Снимок экрана 2025-10-08 154556" src="https://github.com/user-attachments/assets/1102490c-edd8-413f-b8e9-dd97436c1a78" />


Эти переменные показывают, что развитие диабета сильнее всего связано с факторами, отражающими общее состояние здоровья, физическую активность и индекс массы тела.

## Модель 1: Нейронная сеть (PyTorch)

Для решения задачи бинарной классификации была реализована нейронная сеть на PyTorch.
Архитектура:

- Входной слой: 21 нейрон (по числу признаков)

- Скрытые слои: 64 и 128 нейронов

- Активация: LeakyReLU

- Dropout (0.3 и 0.2) для предотвращения переобучения

- Batch Normalization после каждого скрытого слоя

- Выходной слой: 2 нейрона (Softmax)

- Оптимизация:
Adam (lr=1e-4), функция потерь — CrossEntropyLoss, обучение в течение 20 эпох.

Динамика обучения:
Графики потерь и точности показывают стабильное снижение loss и рост accuracy, без признаков переобучения.
На валидации метрики слегка выше, чем на обучении, что говорит о хорошей обобщающей способности модели.
<p align="center">
  <img src="https://github.com/user-attachments/assets/8a3dd184-f0d3-4b6e-a219-378dba6dc95d" width="45%" />
  <img src="https://github.com/user-attachments/assets/24e94f6e-158e-44a4-9acc-475ef7c4286f" width="45%" />
</p>

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.8667  | 0.8673  | 0.8655  |
| F1-score  | 0.4713  | 0.4737  | 0.4727  |
| ROC-AUC   | 0.8312  | 0.8298  | 0.8315  |

Несмотря на умеренное значение F1-score (обусловлено сильным дисбалансом классов), модель достигает высокой точности и устойчивого ROC-AUC около 0.83, что подтверждает её способность распознавать пациентов с диабетом при оптимальном пороге классификации.

# Модель 2: Логистическая регрессия

Логистическая регрессия использовалась как базовая интерпретируемая модель для классификации пациентов по признакам здоровья и образа жизни.
Перед обучением признаки были стандартизированы с помощью StandardScaler, а оптимальный порог вероятности подобран по максимальному значению F1-score на валидационной выборке. Лучший порог — 0.198.

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.8638  | 0.8624  | 0.8640  |
| F1-score  | 0.4595  | 0.4604  | 0.4603  |
| ROC-AUC   | 0.8222  | 0.8218  | 0.8208  |

Модель демонстрирует устойчивые результаты на всех выборках без переобучения. Несмотря на сравнительно невысокое значение F1-score (вследствие дисбаланса классов), логистическая регрессия показала хорошую способность различать пациентов с диабетом (ROC-AUC ≈ 0.82) и может служить надёжной отправной точкой для сравнения с более сложными моделями.

# Модель 3: Решающее дерево (Decision Tree Classifier)

Решающее дерево применялось для выявления простых правил классификации и оценки важности признаков. Использовалась базовая модель без ограничений глубины, что позволило проанализировать склонность алгоритма к переобучению.
Оптимальный порог классификации — 0.406, выбран по максимальному значению F1-score на валидационной выборке.

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.9947  | 0.7950  | 0.7977  |
| F1-score  | 0.9812  | 0.2987  | 0.3062  |
| ROC-AUC   | 0.9999  | 0.5922  | 0.5980  |

Модель полностью переобучилась: на тренировочных данных почти идеальные показатели (Accuracy > 0.99, ROC-AUC ≈ 1.0), но на валидации и тесте производительность резко падает (ROC-AUC около 0.6).
Такое расхождение указывает, что дерево слишком детально подстроилось под обучающую выборку и не способно обобщать данные. В дальнейшем это компенсируется использованием ансамблевых методов — случайного леса и градиентного бустинга.

## Модель 4: Решающее дерево (после подбора гиперпараметров, GridSearchCV)

После выявленного переобучения базовой версии, решающее дерево было оптимизировано с помощью кросс-валидации (GridSearchCV, 5 фолдов).
Перебирались параметры: глубина дерева, минимальное число образцов для разбиения и листа, критерий разбиения и способ выбора сплитов.
Лучший порог классификации по F1-score составил 0.604.

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.7547  | 0.7114  | 0.7067  |
| F1-score  | 0.5267  | 0.4130  | 0.4172  |
| ROC-AUC   | 0.8854  | 0.7616  | 0.7609  |

После настройки гиперпараметров дерево стало заметно стабильнее и перестало переобучаться.
Метрики на валидации и тесте выросли почти в полтора раза по сравнению с базовой моделью, а ROC-AUC приблизился к 0.76.
Оптимизированное дерево сохраняет интерпретируемость, но остаётся ограниченным в сложности выявляемых зависимостей — именно поэтому в дальнейшем применяются ансамблевые методы.

## Модель 5: Случайный лес (Random Forest, после RandomizedSearchCV)

Случайный лес использовался для повышения устойчивости и снижения переобучения по сравнению с отдельным деревом.
Подбор гиперпараметров выполнялся методом случайного поиска (RandomizedSearchCV, 50 комбинаций, 3-кратная кросс-валидация).
Оптимальный порог классификации — 0.525, выбран по максимальному F1-score на валидационной выборке.

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.8548  | 0.7953  | 0.7930  |
| F1-score  | 0.6357  | 0.4626  | 0.4624  |
| ROC-AUC   | 0.9384  | 0.8224  | 0.8206  |

Ансамблирование позволило резко снизить переобучение: показатели на тесте и валидации выровнялись, ROC-AUC вырос до 0.82 — почти как у нейросети.
F1-score также улучшился по сравнению с решающим деревом, что говорит о более сбалансированном распознавании положительного класса.
Модель сохраняет интерпретируемость (через feature importance) и хорошо подходит для медицинских данных с большим числом признаков.

## Модель 6: LightGBM (градиентный бустинг на решающих деревьях)

LightGBM применялся как мощный ансамблевый метод, способный эффективно работать с табличными данными и улавливать нелинейные зависимости между признаками.
Модель обучалась с параметрами: n_estimators=500, learning_rate=0.05, objective='binary', metric='f1', random_state=42, n_jobs=-1.
Оптимальный порог классификации по F1-score — 0.238.

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.8732  | 0.8666  | 0.8681  |
| F1-score  | 0.5042  | 0.4723  | 0.4694  |
| ROC-AUC   | 0.8547  | 0.8298  | 0.8271  |

LightGBM показывает одно из лучших соотношений между точностью и обобщающей способностью.
ROC-AUC на уровне 0.83 подтверждает, что модель хорошо различает пациентов с диабетом и без него, а F1-score — лучший среди всех алгоритмов, протестированных в проекте.
В отличие от случайного леса, LightGBM быстрее обучается и легче настраивается под большие выборки, сохраняя высокую производительность.

## Модель 7: LightGBM (после подбора гиперпараметров, CV)

Для улучшения базовой модели LightGBM был проведён поиск оптимальных гиперпараметров с помощью кросс-валидации. Подбирались глубина деревьев, количество листьев, темп обучения и количество бустинговых итераций.
Итоговая модель обучена с оптимальными параметрами и порогом классификации 0.238, выбранным по максимальному значению F1-score.

Результаты:

| Метрика   | Train   | Val     | Test    |
|-----------|---------|---------|---------|
| Accuracy  | 0.8811  | 0.8658  | 0.8669  |
| F1-score  | 0.5241  | 0.4693  | 0.4685  |
| ROC-AUC   | 0.8679  | 0.8264  | 0.8234  |

После кросс-валидации LightGBM стал немного точнее и устойчивее: Accuracy и F1-score стабильно высоки на всех выборках, а ROC-AUC сохраняется в диапазоне 0.82–0.87.
Модель показывает лучший баланс между переобучением и обобщением, а также демонстрирует наивысшее качество среди всех протестированных алгоритмов.

## Итог и выводы

В проекте проведён полный цикл решения задачи бинарной классификации — от предварительного анализа данных до сравнения нескольких моделей машинного обучения.
На основе анализа можно сделать следующие выводы:

### Качество данных.
Датасет содержит около четверти миллионов наблюдений с выраженным дисбалансом классов: доля здоровых примерно в пять раз выше, чем больных диабетом. Наиболее информативные признаки — HighBP, HighChol, BMI, GenHlth и DiffWalk, что согласуется с медицинской логикой развития болезни.

### Сравнение моделей.

| Модель                   | Accuracy (test) | F1 (test) | ROC-AUC (test) |
|--------------------------|-----------------|-----------|----------------|
| Нейронная сеть           | 0.8655          | 0.4727    | 0.8315         |
| Логистическая регрессия  | 0.8640          | 0.4603    | 0.8208         |
| Решающее дерево          | 0.7977          | 0.3062    | 0.5980         |
| Решающее дерево (CV)     | 0.7067          | 0.4172    | 0.7609         |
| Случайный лес (CV)       | 0.7930          | 0.4624    | 0.8206         |
| LightGBM                 | 0.8681          | 0.4694    | 0.8271         |
| LightGBM (CV)            | 0.8669          | 0.4685    | 0.8234         |

### Интерпретация результатов.

- Нейронная сеть и логистическая регрессия показали наиболее устойчивые и сбалансированные результаты: Accuracy около 0.86, ROC-AUC около 0.83. Эти модели демонстрируют хорошую способность обобщать данные при минимальном переобучении.

- Решающее дерево без настройки резко переобучилось, однако после кросс-валидации его качество существенно выросло — ROC-AUC поднялся до 0.76. Тем не менее, дерево остаётся наименее стабильным из всех алгоритмов.

- Случайный лес показал заметный рост устойчивости по сравнению с отдельным деревом и уверенный ROC-AUC ≈ 0.82, что подтверждает эффективность ансамблевого подхода при работе с несбалансированными выборками.

- LightGBM продемонстрировал лучшую точность (0.8681) и один из самых высоких F1-score (0.4694), сохранив низкий риск переобучения. Однако по F1-score и ROC-AUC лидером остаётся нейросеть (0.4727 и 0.8315 соответственно), что делает её наиболее чувствительной к распознаванию пациентов с диабетом.

### Общие выводы

Все модели показывают схожие значения Accuracy (~0.86–0.87), однако из-за сильного дисбаланса классов метрика F1 остаётся умеренной.

Нейронная сеть — наилучший результат по F1 и ROC-AUC, оптимальна при акценте на распознавании больных.

LightGBM — лидер по Accuracy и общей стабильности.

### Итог:
Проект показывает применимость современных методов машинного обучения для медицинской диагностики диабета.
Наилучшие результаты продемонстрировали нейросеть и LightGBM — модели, сочетающие точность, устойчивость и способность выявлять сложные закономерности в данных.
Построенный конвейер может служить универсальным шаблоном для решения схожих задач в сфере здравоохранения.
